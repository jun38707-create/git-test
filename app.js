// VERSION CONTROL: 7.0 (Context Tracker & Audio Switch)
console.log("APP VERSION: 7.0 - Hidden Text & Audio Recorder");

// --- 1. CRITICAL RECOVERY LAYER (Move to top, No dependencies) ---
window.closeReport = () => {
    const reportOverlay = document.getElementById('report-overlay');
    if (reportOverlay) {
        reportOverlay.style.display = 'none';
        reportOverlay.classList.add('hidden');
    }
};

window.copyReport = () => {
    const reportBody = document.getElementById('report-body');
    if (!reportBody) return;
    const text = reportBody.innerText;
    if (text.includes("ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤") || text.includes("ì‘ì„± ì¤‘")) {
        alert("âš ï¸ ì•„ì§ ë³´ê³ ì„œê°€ ì™„ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!");
        return;
    }
    navigator.clipboard.writeText(text).then(() => {
        alert('ì„±ê³µ! ë³´ê³ ì„œê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ì œ ì‚¼ì„±ë…¸íŠ¸ë‚˜ ì¹´í†¡ì— [ë¶™ì—¬ë„£ê¸°] í•˜ì„¸ìš”!');
        window.closeReport();
    });
};

window.forceAppReload = () => {
    if (confirm('ì•±ì„ ê°•ì œë¡œ ìƒˆë¡œê³ ì¹¨í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n(ì…ë ¥ëœ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)')) {
        const freshUrl = window.location.pathname + '?v=' + new Date().getTime();
        window.location.replace(freshUrl);
    }
};

window.panicReset = () => {
    if (confirm('ğŸš¨ ëª¨ë“  ì„¤ì •ì„ ì´ˆê¸°í™”í•˜ê³  ì•±ì„ ì²˜ìŒ ìƒíƒœë¡œ ë˜ëŒë¦¬ì‹œê² ìŠµë‹ˆê¹Œ?\n(ì €ì¥ëœ API í‚¤ë„ ì‚­ì œë©ë‹ˆë‹¤.)')) {
        localStorage.clear();
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.getRegistrations().then(registrations => {
                for (let r of registrations) r.unregister();
            });
        }
        window.location.reload(true);
    }
};

// --- 2. DOM INITIALIZATION ---
document.addEventListener('DOMContentLoaded', () => {
    const analyzeBtn = document.getElementById('analyze-btn');
    const appStatus = document.getElementById('app-status');
    const ambientOverlay = document.getElementById('ambient-overlay');
    const textInput = document.getElementById('text-input');
    const settingsToggle = document.getElementById('settings-toggle');
    const settingsPanel = document.getElementById('settings-panel');
    const apiKeyInput = document.getElementById('api-key-input');
    const saveKeyBtn = document.getElementById('save-key-btn');
    const reportOverlay = document.getElementById('report-overlay');
    const reportBody = document.getElementById('report-body');
    const flowContainer = document.getElementById('flow-container');
    const saveBtn = document.getElementById('save-btn');
    const pocketBtn = document.getElementById('pocket-btn');
    const pocketOverlay = document.getElementById('pocket-overlay');

    if (appStatus) appStatus.textContent = "âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (v7.0 ë§¥ë½ íŠ¸ë˜ì»¤ & ì˜¤ë””ì˜¤)";

    let isAnalyzing = false;
    let recognition = null;
    
    // De-duplication variables
    let lastProcessedText = "";
    let lastProcessedTime = 0;

    let GEMINI_API_KEY = localStorage.getItem('GEMINI_API_KEY') || '';
    let wakeLock = null;
    let conversationHistory = [];
    let lastTopic = ""; // Track the last topic
    let ghostBubble = null; // For interim results

    if (GEMINI_API_KEY && apiKeyInput) {
        apiKeyInput.value = GEMINI_API_KEY;
    }

    if (settingsToggle) {
        settingsToggle.addEventListener('click', (e) => {
            e.stopPropagation();
            settingsPanel.classList.toggle('hidden');
        });
    }

    if (saveKeyBtn) {
        saveKeyBtn.addEventListener('click', () => {
            GEMINI_API_KEY = apiKeyInput.value.trim();
            localStorage.setItem('GEMINI_API_KEY', GEMINI_API_KEY);
            alert('API í‚¤ê°€ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.');
            settingsPanel.classList.add('hidden');
        });
    }

    // --- Pocket Mode Logic ---
    if (pocketBtn && pocketOverlay) {
        pocketBtn.addEventListener('click', () => {
            pocketOverlay.style.display = 'flex';
            // Try to acquire wake lock
            if ('wakeLock' in navigator) {
                navigator.wakeLock.request('screen').then(lock => {
                    wakeLock = lock;
                }).catch(e => console.error(e));
            }
        });

        // Double tap to exit
        let lastTap = 0;
        pocketOverlay.addEventListener('click', (e) => {
            const currentTime = new Date().getTime();
            const tapLength = currentTime - lastTap;
            if (tapLength < 500 && tapLength > 0) {
                pocketOverlay.style.display = 'none';
                e.preventDefault();
            }
            lastTap = currentTime;
        });
    // --- Audio File Upload & Analysis Logic (v7.0) ---
    const audioUpload = document.getElementById('audio-upload');
    if (audioUpload) {
        audioUpload.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;

            if (!GEMINI_API_KEY) {
                alert("âš ï¸ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.");
                settingsPanel.classList.remove('hidden');
                return;
            }

            // Show Loading in Report Modal
            reportOverlay.style.display = 'flex';
            reportOverlay.classList.remove('hidden');
            reportBody.innerHTML = `
                <div style="text-align:center; padding: 2rem;">
                    <h3 class="pulse">ğŸ§ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...</h3>
                    <p style="font-size: 0.8rem; color: #aaa; margin-top:10px;">íŒŒì¼ í¬ê¸°ì— ë”°ë¼ 10~30ì´ˆ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>AIê°€ ëª©ì†Œë¦¬ë¥¼ ë“£ê³  í™”ìë¥¼ êµ¬ë¶„í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>
                </div>`;

            try {
                // Convert file to Base64
                const base64Audio = await fileToGenerativePart(file);
                
                // Call Gemini 1.5 Flash (Multimodal)
                const transcript = await analyzeAudioWithGemini(base64Audio);
                
                // Display Result
                if (transcript) {
                    reportBody.innerHTML = formatTranscript(transcript);
                    const copyBtn = document.getElementById('copy-report-btn');
                    if (copyBtn) {
                        copyBtn.disabled = false;
                        copyBtn.style.opacity = '1';
                        copyBtn.textContent = 'ë¶„ì„ ê²°ê³¼ ë³µì‚¬';
                    }
                } else {
                    throw new Error("No transcript generated.");
                }

            } catch (error) {
                console.error("Audio Analysis Error:", error);
                reportBody.innerHTML = `<div style="text-align:center; padding: 2rem; color: #f87171;">
                    <h3>âŒ ë¶„ì„ ì‹¤íŒ¨</h3>
                    <p>ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}</p>
                    <p style="font-size: 0.8rem; margin-top: 10px;">íŒŒì¼ì´ ë„ˆë¬´ í¬ê±°ë‚˜(20MB ì´í•˜ ê¶Œì¥), API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.</p>
                </div>`;
            }
            
            // Reset input so same file can be selected again
            audioUpload.value = '';
        });
    }

    async function fileToGenerativePart(file) {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => {
                const base64String = reader.result.split(',')[1];
                resolve({
                    inlineData: {
                        data: base64String,
                        mimeType: file.type
                    }
                });
            };
            reader.onerror = reject;
            reader.readAsDataURL(file);
        });
    }

    async function analyzeAudioWithGemini(audioPart) {
        const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`;
        
        const prompt = `
        Listen to this audio recording of a conversation.
        Task:
        1. Transcribe the conversation exactly into Korean.
        2. Distinguish speakers by voice (e.g., Speaker A, Speaker B).
        3. Format the output cleanly.

        Output Format:
        <h2>ğŸ™ï¸ ëŒ€í™” ë…¹ì·¨ë¡</h2>
        <ul>
        <li><b>í™”ì A:</b> ...message...</li>
        <li><b>í™”ì B:</b> ...message...</li>
        </ul>
        <hr>
        <h3>ğŸ“ ìš”ì•½</h3>
        <p>...summary...</p>
        `;

        const response = await fetch(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{
                    parts: [
                        { text: prompt },
                        audioPart
                    ]
                }]
            })
        });

        const data = await response.json();
        if (data.error) throw new Error(data.error.message);
        return data.candidates[0].content.parts[0].text;
    }

    function formatTranscript(rawText) {
        // Simple formatter to ensure it looks good in HTML
        return rawText.replace(/\n/g, '<br>');
    }


    // --- Speech Recognition & Audio Recording Setup ---
    let mediaRecorder = null;
    let audioChunks = [];

    if ('webkitSpeechRecognition' in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'ko-KR';

        recognition.onstart = async () => {
            isAnalyzing = true;
            analyzeBtn.classList.add('recording');
            analyzeBtn.innerHTML = '<span class="btn-icon">ğŸ›‘</span> <span>ë¶„ì„ ì¤‘ì§€</span>';
            
            // Visual indicator
            ambientOverlay.style.background = `radial-gradient(circle at center, rgba(16, 185, 129, 0.2), transparent 70%)`; // Green tint for context mode
            analyzeBtn.style.background = 'linear-gradient(135deg, #10b981, #059669)';
            
            appStatus.innerHTML = "ğŸ§ <span class='pulse'>ë§¥ë½ ì¶”ì  & ë…¹ìŒ ì¤‘...</span>";

            // Start Audio Recording
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) audioChunks.push(event.data);
                };
                
                mediaRecorder.start();
                console.log("Audio recording started.");
            } catch (err) {
                console.error("Microphone access error for recording:", err);
                alert("âš ï¸ ì˜¤ë””ì˜¤ ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ì§€ë§Œ, ë§¥ë½ ë¶„ì„ì€ ê³„ì†ë©ë‹ˆë‹¤.");
            }

            requestWakeLock();
            if (pocketBtn) pocketBtn.style.display = 'flex';
            if (navigator.vibrate) navigator.vibrate(200); 
        };

        recognition.onend = () => {
            if (isAnalyzing) {
                if (navigator.vibrate) navigator.vibrate(500);
                console.log('Restarting recognition...');
                recognition.start();
            } else {
                // STOPPED INTENTIONALLY
                analyzeBtn.classList.remove('recording');
                analyzeBtn.innerHTML = '<span class="btn-icon">ğŸ™ï¸</span> <span>ì¶”ì  ì‹œì‘</span>';
                analyzeBtn.style.background = '';
                appStatus.innerHTML = "âœ… ì¶”ì  ì¢…ë£Œ";
                ambientOverlay.style.background = '';
                
                if (pocketBtn) {
                    pocketBtn.style.display = 'none';
                    if (pocketOverlay) pocketOverlay.style.display = 'none';
                }
                
                if (navigator.vibrate) navigator.vibrate([100, 50, 100]); 

                // Stop Audio Recording
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                    mediaRecorder.onstop = () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        createAudioDownloadLink(audioBlob);
                    };
                    // Stop all tracks to release mic
                    mediaRecorder.stream.getTracks().forEach(track => track.stop());
                }
            }
        };

        recognition.onresult = (event) => {
            let finalTranscript = '';

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                }
            }

            // v7.0: IGNORE Interim Results (No Ghost Bubble)
            // We only care about finalized text for Context Analysis

            if (finalTranscript) {
                // Haptic Feedback: Context Updated
                if (navigator.vibrate) navigator.vibrate([20]); 
                // Do NOT print text bubbles. Only log for AI.
                logDialogueStream(finalTranscript);
            }
        };

        recognition.onerror = (event) => {
            console.error("Recognition Error:", event.error);
            if (event.error === 'not-allowed') {
                appStatus.innerHTML = "âŒ <span style='color:#f87171'>ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.</span>";
            }
        };
    }

    function createAudioDownloadLink(blob) {
        if (!flowContainer) return;
        
        const url = URL.createObjectURL(blob);
        const now = new Date();
        const filename = `recording_${now.getHours()}${now.getMinutes()}.webm`;
        
        const container = document.createElement('div');
        container.style.textAlign = 'center';
        container.style.marginTop = '20px';
        container.style.padding = '10px';
        container.style.background = 'rgba(255,255,255,0.05)';
        container.style.borderRadius = '10px';

        const msg = document.createElement('p');
        msg.textContent = "ğŸ™ï¸ ë…¹ìŒ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.";
        msg.style.fontSize = '0.9rem';
        msg.style.marginBottom = '10px';

        const a = document.createElement('a');
        a.href = url;
        a.download = filename;
        a.className = 'audio-btn';
        a.innerHTML = `<span>ğŸ’¾ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (${(blob.size / 1024 / 1024).toFixed(2)} MB)</span>`;
        a.style.display = 'inline-flex';

        container.appendChild(msg);
        container.appendChild(a);
        
        // Insert at the VERY TOP of flow container or bottom? 
        // Bottom is better.
        flowContainer.appendChild(container);
        flowContainer.scrollTop = flowContainer.scrollHeight;
    }

    async function requestWakeLock() {
        try {
            if ('wakeLock' in navigator) {
                wakeLock = await navigator.wakeLock.request('screen');
            }
        } catch (err) { }
    }

    function releaseWakeLock() {
        if (wakeLock !== null) {
            wakeLock.release().then(() => { wakeLock = null; });
        }
    }

    if (analyzeBtn) {
        analyzeBtn.addEventListener('click', () => {
            if (!recognition) {
                alert("ğŸš« ì´ ë¸Œë¼ìš°ì €ëŠ” ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
                return;
            }
            if (isAnalyzing) {
                isAnalyzing = false; // Trigger onend logic
                recognition.stop();
            } else {
                isAnalyzing = true;
                conversationHistory = [];
                // Clear flow container except empty msg? 
                // Let's clear it to start fresh
                flowContainer.innerHTML = '<div class="empty-flow" style="display:none"></div>';
                
                try { 
                    recognition.start(); 
                } catch (e) { 
                    console.error(e);
                    isAnalyzing = false;
                }
            }
        });
    }

    // REMOVED stopAnalysis function, integrated into onend logic for cleaner flow


    function addFlowBubble(text, isGhost = false) {
        if (!flowContainer) return;

        // Remove empty state message if exists
        const emptyMsg = flowContainer.querySelector('.empty-flow');
        if (emptyMsg) emptyMsg.remove();

        const bubble = document.createElement('div');
        bubble.className = 'chat-bubble';
        if (isGhost) bubble.classList.add('pending');

        const speakerLabel = document.createElement('span');
        speakerLabel.className = 'bubble-speaker';
        
        // Timestamp as "Speaker"
        const now = new Date();
        const timeStr = now.toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit', second: '2-digit' });
        speakerLabel.textContent = `Time: ${timeStr}`;

        const content = document.createElement('div');
        content.textContent = text;

        bubble.appendChild(speakerLabel);
        bubble.appendChild(content);
        flowContainer.appendChild(bubble);

        // Scroll to bottom
        flowContainer.scrollTop = flowContainer.scrollHeight;

        return bubble; 
    }

    function addTopicDivider(topicText) {
        if (!flowContainer) return;

        const divider = document.createElement('div');
        divider.className = 'topic-divider';
        divider.innerHTML = `<span>ğŸ“Œ ì£¼ì œ: ${topicText}</span>`;
        
        flowContainer.appendChild(divider);
        flowContainer.scrollTop = flowContainer.scrollHeight;
    }

    async function logDialogueStream(text) {
        if (!text.trim()) return;
        
        // --- De-duplication Logic ---
        const now = Date.now();
        if (text === lastProcessedText && (now - lastProcessedTime < 2000)) {
            console.log("Duplicate skipped:", text);
            return;
        }
        lastProcessedText = text;
        lastProcessedTime = now;

        if (!GEMINI_API_KEY) {
            alert("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\nì„¤ì • ì°½ì—ì„œ Google AI Studio í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.");
            if (settingsPanel) settingsPanel.classList.remove('hidden');
            if (apiKeyInput) apiKeyInput.focus();
            appStatus.innerHTML = "âš ï¸ <span style='color:#f87171'>API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.</span>";
            isAnalyzing = false;
            analyzeBtn.innerHTML = '<span class="btn-icon">ğŸ™ï¸</span> <span>ë¶„ì„ ì‹œì‘</span>';
            analyzeBtn.style.background = '';
            return;
        }

        let pendingBubble = null;

        try {
            appStatus.innerHTML = "ğŸ“ <span class='pulse'>ë§¥ë½ ë¶„ì„ ì¤‘...</span>";
            
            // v7.0: Hidden Text Mode (Do NOT add bubble)
            // pendingBubble = addFlowBubble(text, false); 
            
            const context = conversationHistory.slice(-5).map(h => h.text).join(' | ');
            const apiResponse = await callGemini(text, context);
            
            let topicFound = null;

            if (apiResponse) {
                if (apiResponse.isTopicChanged && apiResponse.currentTopic) {
                     topicFound = apiResponse.currentTopic;
                     // Insert divider BEFORE the current bubble if possible, 
                     // but here we just append it after logic or maybe before next?
                     // Let's insert it visually before this bubble if we could, 
                     // but simplified: just add it now or next? 
                     // User asked for "Topic Change" -> Add divider.
                     
                     // Move the bubble down? No, just add divider for NOW.
                     // Actually, if topic changed, it applies to THIS text. 
                     // So strictly it should be above. 
                     // For v6.0 simplified, let's just add it at bottom for next turn?
                     // Or better: Insert before current bubble. 
                     if (pendingBubble) {
                         const divider = document.createElement('div');
                         divider.className = 'topic-divider';
                         divider.innerHTML = `<span>ğŸ“Œ ì£¼ì œ ë³€ê²½: ${topicFound}</span>`;
                         flowContainer.insertBefore(divider, pendingBubble);
                     }
                }
                
                // Refine text if Gemini suggests a cleaner version?
                // For now, keep raw text as user requested reliable input.
            }

            if (topicFound) {
                appStatus.textContent = `ğŸ“Œ ì£¼ì œ: ${topicFound}`;
            }

            // Save to history
            conversationHistory.push({
                speaker: 'neutral',
                speakerTag: 'LOG',
                text: text,
                summary: text 
            });
            if (conversationHistory.length > 100) conversationHistory.shift();

        } catch (error) {
            console.error(error);
            appStatus.textContent = "âš ï¸ ê¸°ë¡ ì™„ë£Œ (AI ì§€ì—°)";
        }
    }

    async function callGemini(text, context) {
        if (!GEMINI_API_KEY) return null;

        const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GEMINI_API_KEY}`;
        
        // v6.0 Prompt: Neutral Logger & Topic Detector
        const prompt = `
        You are a smart conversation logger.
        
        Context: ${context}
        New Input: "${text}"

        Task:
        1. Detect if the TOPIC has successfully changed significantly.
        2. Do NOT try to identify speakers.
        3. Just return the Topic status.

        Output JSON:
        {
            "currentTopic": "Short Topic Title" (or null),
            "isTopicChanged": boolean
        }
        `;

        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    contents: [{ parts: [{ text: prompt }] }]
                })
            });

            const data = await response.json();
            const resultText = data.candidates[0].content.parts[0].text;
            
            const jsonStr = resultText.replace(/```json/g, '').replace(/```/g, '').trim();
            return JSON.parse(jsonStr);
        } catch (error) {
            console.error("Gemini API Error:", error);
            return null;
        }
    }

    // New Save Functionality
    if (saveBtn) {
        saveBtn.addEventListener('click', saveConversation);
    }

    function saveConversation() {
        if (conversationHistory.length === 0) {
            alert("ì €ì¥í•  ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.");
            return;
        }

        let content = "===== ëŒ€í™” ê¸°ë¡ ë¡œê·¸ (ë¹„ë°€ íŒŒíŠ¸ë„ˆ v5.0) =====\n\n";
        const now = new Date();
        content += `ì €ì¥ ì¼ì‹œ: ${now.toLocaleString()}\n\n`;

        conversationHistory.forEach((item, index) => {
             content += `[${item.speakerTag || item.speaker}] ${item.text}\n`;
             if (item.summary && item.summary !== item.text) {
                 // content += `   (ìš”ì•½: ${item.summary})\n`; 
             }
             content += "\n";
        });

        const blob = new Blob([content], { type: "text/plain;charset=utf-8" });
        const a = document.createElement("a");
        a.href = URL.createObjectURL(blob);
        a.download = `conversation_log_${now.getFullYear()}${now.getMonth()+1}${now.getDate()}_${now.getHours()}${now.getMinutes()}.txt`;
        a.click();
    }

    async function generateFinalReport() {
        reportOverlay.style.display = 'flex';
        reportOverlay.classList.remove('hidden');
        const copyBtn = document.getElementById('copy-report-btn');
        if (copyBtn) {
            copyBtn.disabled = true;
            copyBtn.style.opacity = '0.5';
            copyBtn.textContent = 'ì‘ì„± ì¤‘...';
        }
        const fullHistory = conversationHistory.map(h => `[${h.speaker === 'me' ? 'ë‚˜' : 'ìƒëŒ€ë°©'}] ${h.text}`).join('\n');
        const prompt = `ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ'ë¥¼ ë°˜ë“œì‹œ 'í•œêµ­ì–´'ë¡œë§Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        ì œë°œ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡(\`\`\`html)ì„ ë„£ì§€ ë§ê³  ìƒ HTML íƒœê·¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - <h2> íƒœê·¸ë¡œ ì œëª© êµ¬ë¶„
        - <ul>, <li>ë¡œ í•µì‹¬ ë‚´ìš© ì •ë¦¬
        - ğŸ¯ ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
        [ë³´ê³ ì„œ êµ¬ì„±]:
        1. ì „ì²´ì ì¸ ëŒ€í™” ë¶„ìœ„ê¸° ìš”ì•½ (í™”ì ê°„ì˜ ìƒí˜¸ì‘ìš© ì¤‘ì‹¬)
        2. ë†“ì¹˜ì§€ ë§ì•„ì•¼ í•  ê²°ì •ì  ì‹œê·¸ë„
        3. ë‚˜ë¥¼ ìœ„í•œ ì‹¤ì „ ëŒ€í™” ì†”ë£¨ì…˜ ë° í”¼ë“œë°±
        ëŒ€í™” ë‚´ìš©:\n${fullHistory}`;
        const endpoints = [
            { model: "Gemini 2.0 Flash", url: `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}` },
            { model: "Gemini 1.5 Flash", url: `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}` }
        ];
        for (const ep of endpoints) {
            try {
                reportBody.innerHTML = `<div style="text-align:center; padding: 2rem;"><span class="pulse">ğŸ¤– [${ep.model}] ì‘ì„± ì¤‘...</span></div>`;
                const response = await fetchWithTimeout(ep.url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] }),
                    timeout: 20000
                });
                const data = await response.json();
                if (data.candidates && data.candidates[0]) {
                    let resultText = data.candidates[0].content.parts[0].text;
                    resultText = resultText.replace(/```html/g, '').replace(/```/g, '').trim();
                    reportBody.innerHTML = resultText;
                    if (copyBtn) {
                        copyBtn.disabled = false;
                        copyBtn.style.opacity = '1';
                        copyBtn.textContent = 'ë³´ê³ ì„œ ë³µì‚¬';
                    }
                    return;
                }
            } catch (e) { }
        }

        // If all failing, show specific error
        console.error("Report Generation Failed");
        reportBody.innerHTML = `<div style="text-align:center; padding: 1rem;">
            <p>âš ï¸ ë³´ê³ ì„œ ì‘ì„± ì‹¤íŒ¨</p>
            <p style="font-size: 0.8rem; color: #aaa;">ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.</p>
            <button onclick="window.location.reload()" style="margin-top:10px; padding: 5px 10px;">ìƒˆë¡œê³ ì¹¨</button>
        </div>`;
    }

    async function fetchWithTimeout(resource, options = {}) {
        const { timeout = 15000 } = options;
        const controller = new AbortController();
        const id = setTimeout(() => controller.abort(), timeout);
        try {
            const response = await fetch(resource, { ...options, signal: controller.signal });
            clearTimeout(id);
            return response;
        } catch (error) {
            clearTimeout(id);
            throw error;
        }
    }
});
